# GBDT

Термин "триплет" в контексте задачи ранжирования рекомендательных систем обычно относится к набору из трех элементов: запроса, положительного примера и отрицательного примера.

**Запрос**

обычно представляет собой идентификатор пользователя в рекомендательной системе.

**Положительный пример**

- это элемент (например, фильм, книга, товар и т.д.), который пользователь уже оценил положительно или с которым взаимодействовал.

**Отрицательный пример**

- это элемент, который пользователь не оценил или с которым не взаимодействовал, и который, по мнению системы, не соответствует предпочтениям пользователя. Задача ранжирования в этом контексте заключается в том, чтобы обучить модель правильно ранжировать положительные примеры выше отрицательных для данного запроса. Это помогает рекомендательной системе предлагать пользователям наиболее релевантные и интересные им элементы.

## Основные подходы ранжирования

- Pointwise
- Pairwise
- Listwise

### PointWise

Основная идея - свести задачу от $f(u, items)$ к $f(u, i_K)$

- Регрессия - ранжируем по регрессионным значениям типа время просмотра ролика или рейтинг
- Классификация - ранжируем по значениям вероятностей типа вроятность совершения тритмента или перехода к карточки товара

### PairWise

Основная идея - свести задачу от $f(u, items)$ к $f(u, i_K)$

Но для обучения используются два объекта (триплеты: позитивные и негативные примеры) $(u, i_M, i_N)$ и бинарный таргет, $f(u, i_M) > f(u, i_N)$

### ListWise

Основная идея - использовать информацию о целом наборе Items для обучения

Получается из PairWise, если мы считаем ошибку суммарно по парам в рамках одного запроса пользователя

---

# Двухэтапная архитектура

- Генерация кандидатов (что захотим предложить пользователю) более простыми моделями
    - Популярное
    - I2I, U2U
    - ALS
    - LightFM
    - Random
- Реранжирование списка кандидатов с фичами более тяжелой моделью
    - GBDT
    - Neural nets

### Таргет

Позитивные примеры

- Известные взаимодействия
- Порог по рейтингу

Негативные примеры

- Известные взаимодействия с негативной оценкой
    - Порог по рейтингу
    - Возврат после покупки
- Случайные
- На основе простых моделей

### Валидация

- Случайно
- По времени

---

# CatBoost

Objectives (losses):

- RMSE
- QueryRMSE
- PairLogit
- PairLogitPairWise
- YetiRank
- YetiRankPairWise

Metrics:

- Precision@K, Recall@K
- MAP
- DCG, nDCG
- PFound

catboost.Pool - класс для сбора датасета для реранжирования

```python
cb_model = catboost.CatBoost({
	'loss_function': 'YetiRank',
	'learning_rate': 0.1,
	'iterations': 1000,
	'early_stopping_rounds': 30,
	'custom_metric': ['RecallAt:top=1', 'RecallAt:top=10', 'Precision:top-=10']
})

cb_model.fit(
	catboost_pool_train,
	eval_set=catboost_pool_test,
	logging_level='Silent',
	plot=True
)
```

---

## LightGBM

Objectives:

- LambdaRank
- XE_NDCG_MART

Metrics:

- MAP
- nDCG
  $$\frac{1}{l​}\sum^l_{i=1}(-s_ib(x_i)+\frac{1}{2}h_ib(x_i)^2)+\gamma J+\frac{\lambda}2{\sum^J_{j=1}b^2_j}\rightarrow\min_b$$
Разложили исходную функцию потерь ($L(y_i​,a_{N−1}​(x_i​)+b(x_i​))$) на приближение рядом Тейлора

Здесь $J$ - число листьев в дереве $b$, а $b_1,b_2,...,b_J$​ - предсказания в листьях дерева.

- Первое слагаемое регуляризации $\gamma J$ штрафует дерево за большое число листьев
- Второе слагаемое $\frac{\lambda}{2}\sum^J_{j=1}b_j^2$ штрафует за большие предсказания в листьях


- Вторые производные 
- Критерий информативности $H(R)$ зависит от $\mathcal{L}$
- регуляризация деревьев (за число листьев и сумму прогнозов в листьях)
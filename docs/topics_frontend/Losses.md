### Таблица: Функции потерь для подходов ранжирования (Pointwise, Pairwise, Listwise)

| **Тип подхода**    | **Функция потерь**                        | **Формула/Описание**                                                                                     | **Примеры использования**                                                        | **Примечания**                                                                        |
| ------------------ | ----------------------------------------- | -------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------- |
| **Pointwise**      | Mean Squared Error (MSE)                  | \( \mathcal{L} = \frac{1}{N} \sum_{(u,i)} (y_{ui} - \hat{y}_{ui})^2 \)                                   | Регрессия для предсказания рейтингов (например, оценок фильмов).                 | Не учитывает порядок объектов.                                                        |
|                    | Binary Cross-Entropy (BCE)                | \( \mathcal{L} = -\sum_{(u,i)} y_{ui} \log \hat{y}_{ui} + (1 - y_{ui}) \log(1 - \hat{y}_{ui}) \)         | Классификация взаимодействий (клик/не клик).                                     | Чаще используется для неявной обратной связи.                                         |
| **Pairwise**       | Hinge Loss                                | \( \mathcal{L} = \max(0, 1 - (\hat{y}_{u,i^+} - \hat{y}_{u,i^-})) \)                                     | Ранжирование пар (релевантный vs нерелевантный айтем).                           | Используется в SVM-подходах.                                                          |
|                    | Bayesian Personalized Ranking (BPR)       | \( \mathcal{L} = -\sum_{(u,i^+,i^-)} \log \sigma(\hat{y}_{u,i^+} - \hat{y}_{u,i^-}) \)                   | Неявная обратная связь, сравнение пар айтемов.                                   | Оптимизирует AUC.                                                                     |
|                    | WARP (Weighted Approximate-Rank Pairwise) | \( \mathcal{L} = \sum_{(u,i^+)} \log(1 + \sum_{i^-} \exp(\gamma (\hat{y}_{u,i^-} - \hat{y}_{u,i^+}))) \) | Ранжирование с аппроксимацией ранга через негативные сэмплы.                     | Учитывает позицию в ранге (штрафует ошибки в топе сильнее).                           |
| **Listwise**       | ListNet                                   | \( \mathcal{L} = -\sum_{i} P(y_i) \log P(\hat{y}_i) \), где \( P \) — softmax.                           | Ранжирование списка через распределение вероятностей.                            | Использует перекрестную энтропию между распределениями релевантности.                 |
|                    | ListMLE                                   | \( \mathcal{L} = -\log \frac{\exp(\hat{y}_{i^+})}{\sum_{j \in \text{список}} \exp(\hat{y}_j)} \)         | Максимизация правдоподобия корректного порядка списка.                           | Учитывает порядок объектов.                                                           |
|                    | NDCG Loss                                 | \( \mathcal{L} = 1 - \text{NDCG}(\text{предсказанный порядок}, \text{идеальный порядок}) \)              | Оптимизация непосредственно под метрику NDCG.                                    | Сложна для оптимизации из-за недифференцируемости метрики (используют аппроксимации). |
| **Пересекающиеся** | Softmax Cross-Entropy (адаптированная)    | \( \mathcal{L} = -\sum_{i} y_i \log \frac{\exp(\hat{y}_i)}{\sum_j \exp(\hat{y}_j)} \)                    | Может использоваться в **listwise** (ListNet) или **pointwise** (классификация). | Зависит от контекста: для списка — listwise, для отдельных объектов — pointwise.      |
|                    | Triplet Loss                              | \( \mathcal{L} = \max(0, \hat{y}_{u,i^-} - \hat{y}_{u,i^+} + \text{margin}) \)                           | **Pairwise** (сравнение триплетов: якорь, позитивный, негативный).               | Часто используется в задачах metric learning.                                         |

---### **Функции потерь для подходов ранжирования**

---


---

#### **Listwise**  
1. **ListNet**  
   - Оптимизирует распределение вероятностей для всего списка.  
   - Формула: \( \mathcal{L} = -\sum_{i} P(y_i) \log P(\hat{y}_i) \), где \( P \) — softmax.  
   - Пример: Ранжирование веб-страниц.  

2. **ListMLE**  
   - Максимизирует правдоподобие корректного порядка.  
   - Формула: \( \mathcal{L} = -\log \frac{\exp(\hat{y}_{i^+})}{\sum_{j \in \text{список}} \exp(\hat{y}_j)} \).  
   - Пример: Поисковые системы.  

3. **NDCG Loss**  
   - Прямая оптимизация метрики NDCG (через аппроксимации).  
   - Формула: \( \mathcal{L} = 1 - \text{NDCG}(\text{предсказанный порядок}, \text{идеальный порядок}) \).  
   - Пример: Ранжирование с учетом дисконтированного выигрыша.  

---

#### **Общие/Пересекающиеся**  
1. **Softmax Cross-Entropy**  
   - Используется как **pointwise** (классификация) или **listwise** (ListNet).  
   - Формула: \( \mathcal{L} = -\sum_{i} y_i \log \frac{\exp(\hat{y}_i)}{\sum_j \exp(\hat{y}_j)} \).  

2. **Triplet Loss**  
   - Сравнение триплетов: якорь, позитивный, негативный айтем.  
   - Формула: \( \mathcal{L} = \max(0, \hat{y}_{u,i^-} - \hat{y}_{u,i^+} + \text{margin}) \).  
   - Пример: Metric learning для рекомендаций.  

---

**Примечания**:  
- **Pointwise** фокусируется на отдельных объектах, игнорируя порядок.  
- **Pairwise** сравнивает пары объектов.  
- **Listwise** оптимизирует весь список целиком.  
- Некоторые функции (Softmax, Triplet Loss) применяются в нескольких подходах.


#### 1. Hit-rate
$$\large\text{Hitrate} = \frac{\text{\# hits}}{\text{\# hits} + \text{\# misses}} = \frac{\text{TP}}{\text{TP} + \text{FN}}$$ $\small\text{(доля правильных предсказаний модели по сравнению с общим количеством предсказаний)}$
#### 2. HR@k для юзера
 $$\large \text{Hitrate@k} = \frac{\sum^k_{i=1}[y_i = 1]}{|Y_k|}$$ $\text{(для одного юзера)}$
#### 3. HR@k для юзеров
$$\large \text{Hitrate@k} = \frac{1}{|u|}\sum_{u\in U}[\sum^k_{i=1}[y_{ui} = 1] > 0] $$ $\small\text{(доля юзеров, у кого хотя бы 1 рекомендация правильная)}$
#### 4. P@k
$$\large\text{Precision@k}=\frac{\sum^k_{i=1}[y_i=1]}{k}=\frac{\text{Количество релевантных айтемов в топ-k}}{k}$$$\small\text{Сколько из рекомендованных элементов действительно релевантны?}$
#### 5. R@k
$$\large\text{Recall@k}=\frac{\sum^k_{i=1}[y_i=1]}{|Y|}=\frac{\text{Количество релевантных айтемов в топ-k}}{\text{Общее количество релевантных айтемов}}$$$\small\text{Сколько из всех релевантных элементов было найдено в первых k рекомендациях?}$

### Пример

для $u_1$:
- $p@1=0$
- $p@3=\frac{0 + 1 + 0}{3} = \frac{1}{3}$
- $p@5=\frac{0 + 1 + 0 + 1 + 0}{5} =\frac{2}{5}$
- $r@1=0$
- $r@3=\frac{0 + 1 + 0}{3} = \frac{1}{3}$
- $r@5=\frac{0 + 1 + 0 + 1 + 0}{5} =\frac{2}{5}$


для всех $u$:
- $hr@3=1$
- $p@3=\frac{1}{|u|}\sum_{u\in U}p@k_u=\frac{\frac{1}{3} + \frac{2}{3} + \frac{2}{3}}{3}=\frac{5}{9}$
- $r@3=\frac{1}{|u|}\sum_{u\in U}r@k_u=\frac{\frac{1}{3} + \frac{2}{3} + \frac{2}{3}}{3}=\frac{5}{9}$

#### Плюсы:
- интерпритируемость 
- простота
- применимы и к бинарной классификации
- расчет и на юзере и на всей выборке 

#### Минусы:
- чувствительность к порогу $k$
- не учитывает порядок
- бинаризируем оценки релевантности 

Улучшения:

#### 6. AP@k
$\Large\text{Average Precision}:$ $$\Large AP@k = \sum^k_{i=1}\frac{[y_i=1]}{|y_k|}*p@i$$ по каждому релевантному элементу считает p@i, суммируем и делим на релевантные ответы
   в примере AP@7 для $u_1$ $= \frac{0 + \frac{1}{2} + 0 + \frac{2}{4} + 0 + \frac{3}{6} + 0}{3} = 0.5$ 
   
   
   
#### 7. MAP@k
$\Large\text{Mean Average Precision :}$ $$\Large MAP@k = \frac{1}{|u|}\sum_{u\in U}AP@k_u$$ MAP - это AP по всем пользователям/запросам в среднем
#### Плюсы: 
- Учитывает порядок 

#### Минусы:
- $|Y_k| \le k \Rightarrow$ метрика занижается при большом $k$

#### 8.  MNAP@k
$$\large\text{MNAP@k} = \frac{1}{|u|}\sum_{u\in U}\frac{1}{\min(n_u, k)}*\sum^k_{i=1}y_i * p@i_u$$ $\small\text{где } n_u \text{ - число айтемов, с которыми юзер взаимодействовал}$


#### 9. DCG@k
DCG оценивает, насколько полезны (релевантны) объекты в топ-kkk ранжировании, с учетом того, что **более важные элементы должны стоять выше**.

**Почему дисконтирование?**  
Люди чаще обращают внимание на первые результаты, поэтому чем дальше находится элемент, тем меньший вклад он вносит в оценку качества ранжирования.

$\Large\text{Discounted Cumulative Gain:}$ $$\large\text{DCG@k} = \sum_{i=1}^kg(y_i)^{\text{функция прироста}}*d(i)^{\text{регуляризатор discount}}=\sum_{i=1}^{k}\frac{2^{y_i}-1}{\log(i+1)}$$
#### 10. nDCG@k
NDCG оценивает, насколько хорошо отсортированы рекомендованные элементы по сравнению с идеальным порядком. 

$\Large\text{normalized Discounted Cumulative Gai:}$ $$\large\text{nDCG@k}=\frac{\text{DCG@k}}{\text{IDCG@k}^{\text{идеальное ранжирование}}}$$




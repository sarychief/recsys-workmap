### Модель: _LightFM (2015)_
> _Использует и коллаборативные и контентные фичи._

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-S4fQj-eEsAl1MWwzS_mGQ.png)
#### Полное описание  
__Формализация:__
- $U$ - множество пользователей
- $I$ - множество объектов 
- $F^U$ - множество признаков пользователей
- $F^I$ - множество признаков айтемов

Все пары $(u, i) \in U \times I$ - это объединение всех положительных $S^+$ и отрицательных $S^-$ интеракций 
Каждый пользователь описан набором заранее известных признаков (мета данных) $f_u \subset F^U$, то же самое для объектов $f_i \subset F^I$ 

#### Работа алгоритма в общем виде
__Шаги:__  
1. Матрицу юзер айтем раскладываем на матрицу $FM \in \mathbb{R}^{n\times m}$:
	1. $m$ столбцы - 4 компоненты: число юзеров, чиисло айтемов, число фичей, скор
	2. $n$ строки количество взаимодействий (ненулей в исходной матрице ало)
2. Предсказание: $$f(x) = w_0 + \sum^P_{p=1}w_px_p + \sum^{P-1}_{p=1}\sum^{P}_{q=p+1}\langle v_p, v_q\rangle x_px_q$$ Эта формула учитывает **все попарные взаимодействия признаков**.


#### Работа алгоритма формата FM  (для implicit и просто понятнее)
__Шаги:__
1. Для каждого признака мы создаем вектор размерности $d$ отдельно для пользователя $e^U_f$ и отдельно для айтема $e^I_f$

2. Латентное представление пользователя и объекта представлено суммой его латентных векторов признаков: $$q_u = \sum_{j\in f_u}e^U_j$$ 
$$p_i=\sum^{}_{j\in f_i}e^I_j$$
	- признаки это пол для юзера и цена для айтема 
	- пример латентного вектора юзера $q_u​=e_{Москва​}+e_{25}​+e_{мужской}​$.

1. Так же считаем смещения по пользователем и объектом: $$b_u = \sum_{j\in f_u}b^U_j$$ 
$$b_i = \sum_{j \in f_i}b^I_j$$
	- $b_u$ отражает общую активность пользователя (например, склонность к покупкам).
	- $b_i$ отражает популярность айтема (например, все любят этот товар).
	- нормального пояснения че такое $b^U$ и $b^I$ я не нашел :(
	
1. Предсказание модели будет считаться через скалярное произведение эмбедингов пользователя и объекта + смещения и передаваться в сигмоиду для получения вероятности: $$\hat r_{ui}=\sigma(q_u^T p_i + b_u + b_i)$$ 
2. Учимся на BCE-loss на SGD: $$\mathcal{L}=−\frac{1}{N}​\sum_{(u,i)\in D}[y_{ui}\log\hat r_{ui}​+(1−y_{ui}​)\log(1−\hat r_{ui}​)]$$

#### Параметры алгоритма
- 
- 

##### Пример работы  
$$$$

##### Пример кода
```python
```

#### Особенности алгоритма
- В оригинальной статье только категориальные фичи (из-за каждому признаку нужно сопоставлять какой-то эмбединг, поэтому с числовыми признаками непонятно что делать)
- 